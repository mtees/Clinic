# -*- coding: utf-8 -*-
"""
Created on Tue Nov  8 13:33:01 2022

@author: mjtee
"""

import os
import numpy as np

import torch
from torch.optim import SGD
from torchvision import models
import matplotlib.pyplot as plt

from torchvision import transforms
from PIL import Image

from misc_functions import preprocess_image, recreate_image, save_image

import os

import csv

import torch
import torch.nn as nn
import torchvision
from torchvision import models, transforms, utils
from torch.autograd import Variable
import numpy as np
import matplotlib.pyplot as plt
import scipy.misc
from PIL import Image
import json
%matplotlib inline

activations = []

os.environ['KMP_DUPLICATE_LIB_OK']='True'

img = Image.open("C://Users//mjtee//OneDrive//Documents//Python Scripts//pytorch-cnn-visualizations-master//generated//class_130//c_130_iter_749.png")
#img2 = Image.open("C://Users//mjtee//OneDrive//Documents//Python Scripts//pytorch-cnn-visualizations-master//generated//class_130//c_130_iter_10.png")

plt.imshow(img)
#plt.imshow(img2)

img=transforms.functional.pil_to_tensor(img)
#img2=transforms.functional.pil_to_tensor(img2)

img.shape
# plt.imshow(img)

pretrained_model = models.alexnet(pretrained=True)

img = img[None,:,:,:]
#img2 = img2[None,:,:,:]
data=torch.cat([img], dim=0).to(torch.float32)
prediction = pretrained_model(data)

print (prediction)

for i, p in enumerate(prediction):
    max_pred_label = int(torch.max(p.data, 0)[1])
    max_pred_activation = prediction[i, max_pred_label]

# total =1

# prediction = torch.nn.functional.softmax(prediction, dim=1)
# for i, p in enumerate(prediction):
#     if img[i] == torch.max(p.data, 0)[1]:
#        # total = total + 1
        
# os.listdirectory

# path = "C:\\Users\mjtee\OneDrive\Documents\Python Scripts\pytorch-cnn-visualizations-master\generated\class_130_blurfreq_4_blurrad_1_wd0.0001"
# list_dir=os.listdir(path)

# print(list_dir)
# >>['img1.png','img2.png','img3.png']

# for i, img_name in enumerate(list_dir):
#     image=Image.open(str(folder_path+img_name))
#     #append to a list or numpy array
#     #save pred_list as csv

Path = "C:\\Users\mjtee\OneDrive\Documents\Python Scripts\pytorch-cnn-visualizations-master\generated\FinalPictures"
list_dir=os.listdir(Path)
print(list_dir)


for name in list_dir:
    img = Image.open(Path + "\\" + name)
    plt.imshow(img)
    plt.show()
    img = transforms.functional.pil_to_tensor(img)

    img.shape

    pretrained_model = models.alexnet(pretrained=True)

    img = img[None,:,:,:]

    data=torch.cat([img], dim=0).to(torch.float32)

    prediction = pretrained_model(data)

    for i, p in enumerate(prediction):
        max_pred_label = int(torch.max(p.data, 0)[1])
        max_pred_activation = prediction[i, max_pred_label]
        print(max_pred_label)
        print(max_pred_activation.item())
        
        activation = max_pred_activation.item()
        label = max_pred_label
        activations.append({ 
                            'pred_label': label, 
                            'act': activation})
        
        
#printing activations into a csv
#source: https://www.codingem.com/python-write-to-csv-file/ 

# # 1. step
# spreadsheet = 'C:\\Users\mjtee\OneDrive\Documents\Python Scripts\pytorch-cnn-visualizations-master\generated\activations.csv'
# with open(spreadsheet, 'w') as file: 
# #opens files, 'w' or 'r' determines whether it will read or write to that file
#     # 2. step
#     writer = csv.writer(file)
#     # 3. step
#     data = ["This", "is", "a", "Test"]
#     writer.writerow(data)

# for loop for each image here
#for i in img:
        # get predicted label and activation
        # Append results dictionary to activations list
        
# end for loop

fieldnames = ['pred_label', 'act']

# Generates the CSV based off the a list of dictionaries. Added Row by Row
# Activations look like this:
# [{'type':'deepdream', 'name':'class_130', 'pred_label_name':'flamingo', 'pred_label':130, 'act':13052}
#  {'type':'deepdream', 'name':'class_152', 'pred_label_name':'tree', 'pred_label':152, 'act':12352}]
with open('activations.csv', 'w',  newline='') as csvfile:
    writer = csv.DictWriter(csvfile, fieldnames = fieldnames) # Create a writer with specific column names
    writer.writeheader() # Write column names
    writer.writerows(activations) # Write data
    
#define image transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=0., std=1.)
])  

#load image
image = Image.open(str("C://Users//mjtee//OneDrive//Documents//Python Scripts//pytorch-cnn-visualizations-master//generated//class_130//c_130_iter_749.png"))
plt.imshow(image)

#load model
model = models.resnet18(pretrained=True)
print(model)

# we will save the conv layer weights in this list
model_weights =[]
#we will save the 49 conv layers in this list
conv_layers = []
# get all the model children as list
model_children = list(model.children())
#counter to keep count of the conv layers
counter = 0
#append all the conv layers and their respective wights to the list
for i in range(len(model_children)):
    if type(model_children[i]) == nn.Conv2d:
        counter+=1
        model_weights.append(model_children[i].weight)
        conv_layers.append(model_children[i])
    elif type(model_children[i]) == nn.Sequential:
        for j in range(len(model_children[i])):
            for child in model_children[i][j].children():
                if type(child) == nn.Conv2d:
                    counter+=1
                    model_weights.append(child.weight)
                    conv_layers.append(child)
print(f"Total convolution layers: {counter}")
print("conv_layers")

#check for gpu
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

#apply transformation
image = transform(image)
print(f"Image shape before: {image.shape}")
image = image.unsqueeze(0)
print(f"Image shape after: {image.shape}")
image = image.to(device)

#generate feature map
outputs = []
names = []
for layer in conv_layers[0:]:
    image = layer(image)
    outputs.append(image)
    names.append(str(layer))
print(len(outputs))
#print feature_maps
for feature_map in outputs:
    print(feature_map.shape)
    
#covert to 2D tensor
processed = []
for feature_map in outputs:
    feature_map = feature_map.squeeze(0)
    gray_scale = torch.sum(feature_map,0)
    gray_scale = gray_scale / feature_map.shape[0]
    processed.append(gray_scale.data.cpu().numpy())
for fm in processed:
    print(fm.shape)
    
#plotting feature maps and save
fig = plt.figure(figsize=(30, 50))
for i in range(len(processed)):
    a = fig.add_subplot(5, 4, i+1)
    imgplot = plt.imshow(processed[i])
    a.axis("off")
    a.set_title(names[i].split('(')[0], fontsize=30)
plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')
